#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import streamlit as st
from openai import OpenAI
import os
import json
from datetime import datetime
from pathlib import Path

# è¨­å®šé é¢é…ç½®
st.set_page_config(
    page_title="Lisaè€å¸«å°ˆå±¬æ–‡æ¡ˆåŠ©æ‰‹",
    page_icon="ğŸ“",
    layout="wide",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': None
    }
)

# éš±è— Streamlit å³ä¸Šè§’é¸å–®å’Œ footer
hide_streamlit_style = """
<style>
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}
header {visibility: hidden;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯
@st.cache_resource
def init_openai_client():
    """åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯ï¼ˆä½¿ç”¨å¿«å–é¿å…é‡è¤‡å»ºç«‹ï¼‰"""
    try:
        # å„ªå…ˆä½¿ç”¨ Streamlit secretsï¼Œæœ¬åœ°é–‹ç™¼æ™‚ä½¿ç”¨ç’°å¢ƒè®Šæ•¸
        api_key = st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY"))
        if not api_key:
            st.error("âŒ æœªè¨­å®š OPENAI_API_KEY")
            st.stop()
        return OpenAI(api_key=api_key)
    except Exception as e:
        st.error(f"âŒ ç„¡æ³•åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯: {e}")
        st.stop()

# å–å¾— Prompt é…ç½®
def get_prompt_config():
    """å–å¾— Prompt ID å’Œç‰ˆæœ¬ï¼ˆå„ªå…ˆä½¿ç”¨ secretsï¼‰"""
    prompt_id = st.secrets.get("PROMPT_ID", "pmpt_68f663c9400081968c77a12c68f176e80438728839e32f32")
    prompt_version = st.secrets.get("PROMPT_VERSION", "6")
    return prompt_id, prompt_version

# åˆå§‹åŒ–
client = init_openai_client()
PROMPT_ID, PROMPT_VERSION = get_prompt_config()

# åˆå§‹åŒ– session stateï¼ˆåƒ…åœ¨ç€è¦½å™¨ session ä¸­ä¿å­˜ï¼Œä¸è·¨ä½¿ç”¨è€…ï¼‰
if "messages" not in st.session_state:
    st.session_state.messages = []

if "api_logs" not in st.session_state:
    st.session_state.api_logs = []

# ä¿ç•™æ–‡å­—åŸå§‹æ ¼å¼
def format_text_with_breaks(text):
    """ä¿ç•™æ–‡å­—çš„åŸå§‹æ ¼å¼ï¼Œä¸åšä»»ä½•æ›¿æ›"""
    return text if text else ""

# å´é‚Šæ¬„åŠŸèƒ½
with st.sidebar:
    st.header("âš™ï¸ åŠŸèƒ½")

    if st.button("ğŸ—‘ï¸ æ¸…é™¤å°è©±æ­·å²", use_container_width=True):
        st.session_state.messages = []
        st.session_state.api_logs = []
        st.rerun()

    st.divider()

    st.subheader("ğŸ“Š å°è©±çµ±è¨ˆ")
    st.metric("è¨Šæ¯æ•¸é‡", len(st.session_state.messages))

    st.divider()

    st.subheader("ğŸ’¡ ä½¿ç”¨èªªæ˜èˆ‡ç¯„ä¾‹")

    st.markdown("### å¦‚ä½•ä½¿ç”¨")
    st.markdown("""
    1. åœ¨ä¸‹æ–¹è¼¸å…¥æ¡†è¼¸å…¥è¨Šæ¯
    2. æŒ‰ Enter ç™¼é€
    3. AI æœƒè¨˜ä½å®Œæ•´å°è©±ä¸Šä¸‹æ–‡
    4. æ¯å€‹ä½¿ç”¨è€…çš„å°è©±è¨˜éŒ„æ˜¯ç¨ç«‹çš„
    5. é—œé–‰åˆ†é å¾Œå°è©±è¨˜éŒ„æœƒæ¸…é™¤
    """)

    st.markdown("### ğŸ“ ç¯„ä¾‹ Prompt")
    st.code("""è«‹å¹«æˆ‘åƒç…§ä»¥ä¸‹å…§å®¹æ”¹å¯«ä¸€ç¯‡é›»å­å ±

ä¸»é¡Œï¼š2025å¹´æ•¸æ“šåˆ†æå¸«å¿…å‚™æŠ€èƒ½

å…§å®¹ç´ æï¼š
1. æŒæ¡ AI è½åœ°æ‡‰ç”¨è¶¨å‹¢
2. äº†è§£å…¬å¸ç¾æ³åœ¨ AI ç™¼å±•å„ªå‹¢ï¼ˆä»¥ Shutterstock ç‚ºä¾‹ï¼‰
3. å–„ç”¨è‡ªå‹•åŒ–æ¸›å°‘æ—¥å¸¸æ¡é›†è³‡æ–™å·¥ä½œ""", language="text")

    st.divider()

    # API å‘¼å« Log é¡¯ç¤ºå€
    with st.expander("ğŸ“‹ API å‘¼å«è¨˜éŒ„", expanded=False):
        if st.session_state.api_logs:
            st.caption(f"å…± {len(st.session_state.api_logs)} ç­†è¨˜éŒ„")
            for idx, log in enumerate(reversed(st.session_state.api_logs), 1):
                with st.container():
                    st.markdown(f"**#{len(st.session_state.api_logs) - idx + 1}** - {log['timestamp']}")
                    st.json(log['data'])
                    if idx < len(st.session_state.api_logs):
                        st.divider()
        else:
            st.info("å°šç„¡ API å‘¼å«è¨˜éŒ„")

# æ¨™é¡Œå’Œèªªæ˜
st.title("ğŸ“ Lisaè€å¸«å°ˆå±¬æ–‡æ¡ˆåŠ©æ‰‹")
st.caption(f"ä½¿ç”¨ OpenAI Responses API | Prompt ç‰ˆæœ¬: {PROMPT_VERSION}")

# é¡¯ç¤ºå°è©±æ­·å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # è™•ç†æ›è¡Œä¸¦é¡¯ç¤º
        formatted_content = format_text_with_breaks(message["content"])
        st.markdown(formatted_content)

# èŠå¤©è¼¸å…¥æ¡†
if prompt := st.chat_input("è¼¸å…¥è¨Šæ¯..."):
    # é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯
    with st.chat_message("user"):
        formatted_prompt = format_text_with_breaks(prompt)
        st.markdown(formatted_prompt)

    # åŠ å…¥åˆ°å°è©±æ­·å²
    st.session_state.messages.append({"role": "user", "content": prompt})

    # é¡¯ç¤º AI å›æ‡‰
    with st.chat_message("assistant"):
        with st.spinner("Lisaè€å¸«æ­£åœ¨æ€è€ƒä¸­..."):
            try:
                # æº–å‚™å®Œæ•´çš„å°è©±æ­·å²ï¼ˆä¸Šä¸‹æ–‡è¨˜æ†¶ï¼‰
                # æ³¨æ„ï¼šOpenAI Responses API ç›®å‰å¯èƒ½ä¸æ”¯æ´å¤šè¼ªå°è©±
                # é€™è£¡æˆ‘å€‘å°‡æ­·å²å°è©±åˆä½µåˆ° input ä¸­
                conversation_context = ""
                if len(st.session_state.messages) > 1:
                    # å°‡ä¹‹å‰çš„å°è©±æ•´ç†æˆä¸Šä¸‹æ–‡
                    for msg in st.session_state.messages[:-1]:  # æ’é™¤å‰›å‰›åŠ å…¥çš„æœ€æ–°è¨Šæ¯
                        role_name = "ä½¿ç”¨è€…" if msg["role"] == "user" else "åŠ©æ‰‹"
                        conversation_context += f"{role_name}: {msg['content']}\n\n"

                # ç•¶å‰è¼¸å…¥
                current_input = f"{conversation_context}ä½¿ç”¨è€…: {prompt}"

                # è¨˜éŒ„ API è«‹æ±‚é–‹å§‹æ™‚é–“
                request_time = datetime.now()

                # å‘¼å« OpenAI Responses API
                response = client.responses.create(
                    prompt={
                        "id": PROMPT_ID,
                        "version": PROMPT_VERSION
                    },
                    input=current_input
                )

                # è¨˜éŒ„ API å›æ‡‰æ™‚é–“
                response_time = datetime.now()
                elapsed_time = (response_time - request_time).total_seconds()

                # è§£æå›æ‡‰
                ai_message = ""
                response_items = []

                # å˜—è©¦ä¸åŒçš„æ–¹å¼ç²å–å…§å®¹
                if hasattr(response, 'output'):
                    if isinstance(response.output, list):
                        response_items = response.output
                    elif isinstance(response.output, str):
                        ai_message = response.output
                elif hasattr(response, 'data'):
                    response_items = response.data if isinstance(response.data, list) else [response.data]
                elif hasattr(response, 'items'):
                    response_items = response.items if isinstance(response.items, list) else [response.items]
                elif isinstance(response, list):
                    response_items = response

                # è§£æ response_items
                if not ai_message and response_items:
                    for item in response_items:
                        if (hasattr(item, 'type') and item.type == 'message' and
                            hasattr(item, 'status') and item.status == 'completed'):
                            if hasattr(item, 'content') and item.content:
                                for content_item in item.content:
                                    if hasattr(content_item, 'type') and content_item.type == 'output_text':
                                        if hasattr(content_item, 'text'):
                                            ai_message += content_item.text

                # å¦‚æœé‚„æ˜¯æ²’æœ‰å…§å®¹
                if not ai_message:
                    ai_message = "æŠ±æ­‰ï¼Œç„¡æ³•è§£æ AI å›æ‡‰ã€‚"

                # è¨˜éŒ„å®Œæ•´çš„ API å‘¼å« log
                api_log = {
                    "timestamp": request_time.strftime("%Y-%m-%d %H:%M:%S"),
                    "data": {
                        "request": {
                            "prompt_id": PROMPT_ID,
                            "prompt_version": PROMPT_VERSION,
                            "input_preview": prompt[:100] + "..." if len(prompt) > 100 else prompt,
                            "input_length": len(current_input),
                            "context_messages": len(st.session_state.messages) - 1
                        },
                        "response": {
                            "success": True,
                            "output_preview": ai_message[:200] + "..." if len(ai_message) > 200 else ai_message,
                            "output_length": len(ai_message),
                            "elapsed_time_seconds": round(elapsed_time, 2)
                        }
                    }
                }
                st.session_state.api_logs.append(api_log)

                # è™•ç†æ›è¡Œä¸¦é¡¯ç¤ºå›æ‡‰
                formatted_ai_message = format_text_with_breaks(ai_message)
                st.markdown(formatted_ai_message)

                # åŠ å…¥åˆ°å°è©±æ­·å²ï¼ˆå„²å­˜åŸå§‹å…§å®¹ï¼‰
                st.session_state.messages.append({"role": "assistant", "content": ai_message})

            except Exception as e:
                error_msg = f"âŒ éŒ¯èª¤: {str(e)}"
                st.error(error_msg)
                st.session_state.messages.append({"role": "assistant", "content": error_msg})

                # è¨˜éŒ„éŒ¯èª¤åˆ° API log
                error_log = {
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "data": {
                        "request": {
                            "prompt_id": PROMPT_ID,
                            "prompt_version": PROMPT_VERSION,
                            "input_preview": prompt[:100] + "..." if len(prompt) > 100 else prompt
                        },
                        "response": {
                            "success": False,
                            "error": str(e),
                            "error_type": type(e).__name__
                        }
                    }
                }
                st.session_state.api_logs.append(error_log)
